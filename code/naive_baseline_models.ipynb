{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting using naive models and ETS (from statsforecast)\n",
    "\n",
    "Overall WindowAverage with window size of 21 / 28 performed the best, even compared to ML and SARIMA according to kaggle RMSE, followed by HoltWinters (ETS). We would recommend using these naive models as a very decent baseline regressor because it is computationally cheap to run (window average took about 1.5 mins to train on the entire train csv), and does not require much data manipulation before training.\n",
    "\n",
    "Practically speaking, with a window average of 21, it means that to figure out how many items to stock the shops, FairStorage should take the average of the items sold in the past 3 weeks, and that would be a good minimum number to stock the shelves with.\n",
    "\n",
    "Models used, along with kaggle score: \n",
    "- Naive (3.03)\n",
    "- SeasonalNaive (2.73)\n",
    "- WindowAverage (2.27)\n",
    "- SeasonalWindowAverage (2.48)\n",
    "- HoltWinters (2.29)\n",
    "\n",
    "Additionally we tried just using the last 21 days of the train data as the forecast data, and it obtained a relatively decent score at 2.81. This was much better than SARIMA which were the first type of models that we tried doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = r\"../datasets/train.csv\"\n",
    "PRICES_CSV_PATH = r\"../datasets/prices.csv\"\n",
    "CAL_CSV_PATH = r\"../datasets/calendar.csv\"\n",
    "SAMPLE_CSV_PATH = r\"../datasets/sample_submission.csv\"\n",
    "\n",
    "EXPORT_PATH = r\"../submissions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tristan\\Desktop\\Assignments\\ADS\\ads-final-project\\ads_env\\lib\\site-packages\\statsforecast\\core.py:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive, SeasonalNaive, WindowAverage, SeasonalWindowAverage, HoltWinters\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation, convering to relevant datatypes and preparing long form data for training models (one row is one item for one day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_sample_sub = pd.read_csv(SAMPLE_CSV_PATH)\n",
    "df_cal = pd.read_csv(CAL_CSV_PATH)\n",
    "\n",
    "# Merge d to get dates\n",
    "df_dates = pd.DataFrame(columns = [\"d\"], data = df_train.columns[6:])\n",
    "df_dates = df_dates.merge(df_cal[[\"date\", \"d\"]], on = \"d\", how = \"left\")\n",
    "\n",
    "# Convert to appropriate datatypes\n",
    "df_dates[\"d\"] = df_dates[\"d\"].astype(\"string\")\n",
    "df_dates[\"date\"] = pd.to_datetime(df_dates[\"date\"])\n",
    "\n",
    "string_features = [\"id\", \"item_id\", \"subcat_id\", \"category_id\", \"store_id\", \"region_id\"]\n",
    "for f in string_features :\n",
    "    df_train[f] = df_train[f].astype(\"string\")\n",
    "\n",
    "df_cal[\"date\"] = pd.to_datetime(df_cal[\"date\"])\n",
    "df_cal[\"weekday\"] = df_cal[\"weekday\"].astype(\"string\")\n",
    "df_cal[\"d\"] = df_cal[\"d\"].astype(\"string\")\n",
    "df_cal[\"wm_yr_wk\"] = df_cal[\"wm_yr_wk\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_positive(s) :\n",
    "    \"\"\"\n",
    "    Function to change values to 0 if negative, if not round to nearest int. Used for forecast dataframe that returns non-positive / floats.\n",
    "    s: Pandas series\n",
    "    \"\"\"\n",
    "    s[s < 0 ] = 0\n",
    "    s = s.round().astype(int)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(y_true, y_pred) :\n",
    "    \"\"\"\n",
    "    Function to print the rmse of a prediction. Accepts 2 pandas series.\n",
    "    \"\"\"\n",
    "    print(np.sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert predictions into submission csv\n",
    "def convert_to_sub_csv(preds_df, method) :\n",
    "    \"\"\"\n",
    "    Converts a forecast from the format given by statsforecast, to a submission format for kaggle. \n",
    "    preds_df: forecasted df straight from statsforecast output.\n",
    "    method: statsforecast method used to generate forecasts (relevant column name of preds_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_converted = preds_df[[\"unique_id\", \"ds\", method]].pivot(index = \"unique_id\", columns = \"ds\", values = method)\n",
    "\n",
    "    # Change col names back to day ints\n",
    "    day_to_d = dict(zip(list(df_converted.columns), list(df_sample_sub.columns[1:])))\n",
    "    df_converted = df_converted.rename(day_to_d, axis = 1).reset_index()\n",
    "\n",
    "    # Round up to nearest int\n",
    "    df_converted.iloc[:, 1:] = df_converted.iloc[:, 1:].round().astype(int)    \n",
    "\n",
    "    # Sort into the original ordering by ID\n",
    "    df_converted[[\"category\", \"store\", \"num\", \"region\", \"num_2\"]] = df_converted[\"unique_id\"].str.split(\"_\", expand = True)\n",
    "    df_converted[\"region\"] = pd.Categorical(df_converted[\"region\"], [\"East\", \"Central\", \"West\"])\n",
    "    df_converted = df_converted.sort_values(by = [\"region\", \"num_2\", \"category\", \"store\", \"num\"])\n",
    "    df_converted = df_converted.drop([\"category\", \"store\", \"num\", \"region\", \"num_2\"], axis =1)\n",
    "\n",
    "    # Rename ID col\n",
    "    df_converted = df_converted.rename(columns = {\"unique_id\" : \"id\"})\n",
    "\n",
    "    return df_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_dict = dict(zip(list(df_dates[\"d\"]), list(df_dates[\"date\"])))\n",
    "df_train_dates = df_train.rename(dates_dict, axis = 1)\n",
    "\n",
    "df_naive_train = df_train_dates[[\"id\"] + list(df_train_dates.columns[6:])].melt(id_vars = [\"id\"], var_name= \"ds\", value_name = \"y\")\n",
    "df_naive_train = df_naive_train.rename(columns = {\"id\":\"unique_id\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with naive models\n",
    "\n",
    "For each model, we recorded the performance using 2 methods, \n",
    "- the first was RMSE on a 80/20 split, \n",
    "- the second was training on the entire train.csv and producing a 21 day forecast, and capturing the RMSE from kaggle.\n",
    "\n",
    "The train / test set split was from train.csv split at 2015-01-29, since estimated to provide a 80/20 split given the range of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 80% split point between the start and end points of train dataset\n",
    "end_date = df_naive_train[\"ds\"].iloc[-1] \n",
    "start_date = df_naive_train[\"ds\"].iloc[0] \n",
    "split_date = (end_date - start_date) * 0.8 + start_date\n",
    "\n",
    "# Split into train and validation sets\n",
    "train = df_naive_train.loc[df_naive_train['ds'] < split_date]\n",
    "valid = df_naive_train.loc[(df_naive_train['ds'] >= split_date)]\n",
    "\n",
    "# Number of forecast steps for 20% forecast test\n",
    "h = valid['ds'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with WindowAverage (for window sizes of 12, 14, 21, 28)\n",
    "\n",
    "Best model overall for our team, with window average = 21 the best performing (kaggle score = 2.27) across the different window sizes. We compared WindowAverage with other naive models such as naive, seasonal naive, and seasonal window average (predictions were compared using the Kaggle score). In the interests of keeping the notebook short, the code for these other models are not reproduced here. We only present the code for the best model.\n",
    "\n",
    "WindowAverage might be the best compared to SARIMA or ML because it is computationally less intensive than the other methods, and makes it able to train on the entire dataset. \n",
    "\n",
    "However, not sure why WindowAverage outperforms the other seasonal models, when in fact we would expect the seasonal models to better capture the seasonality we detected in the EDA. This is worth further investigation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on the entire train dataset and export for the next 21 days (uncomment lines to export csv)\n",
    "\n",
    "NOTE: Takes about 6 mins to run the below chunk of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_12 = StatsForecast(models=[WindowAverage(window_size=12)],\n",
    "                      freq='D', n_jobs=-1)\n",
    "\n",
    "wa_14 = StatsForecast(models=[WindowAverage(window_size=14)],\n",
    "                      freq='D', n_jobs=-1)\n",
    "\n",
    "wa_21 = StatsForecast(models=[WindowAverage(window_size=21)],\n",
    "                      freq='D', n_jobs=-1)\n",
    "\n",
    "wa_28 = StatsForecast(models=[WindowAverage(window_size=28)],\n",
    "                      freq='D', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_12_pred = wa_12.forecast(h=21, df = df_naive_train)\n",
    "wa_12_pred = wa_12_pred.reset_index()\n",
    "wa_12_pred = convert_to_sub_csv(wa_12_pred, \"WindowAverage\")\n",
    "# wa_12_pred.to_csv(EXPORT_PATH+\"/naive_models/wa_12.csv\", header=True, index=False)\n",
    "\n",
    "wa_14_pred = wa_14.forecast(h=21, df = df_naive_train)\n",
    "wa_14_pred = wa_14_pred.reset_index()\n",
    "wa_14_pred = convert_to_sub_csv(wa_14_pred, \"WindowAverage\")\n",
    "# wa_14_pred.to_csv(EXPORT_PATH+\"/naive_models/wa_14.csv\", header=True, index=False)\n",
    "\n",
    "wa_21_pred = wa_21.forecast(h=21, df = df_naive_train)\n",
    "wa_21_pred = wa_21_pred.reset_index()\n",
    "wa_21_pred = convert_to_sub_csv(wa_21_pred, \"WindowAverage\")\n",
    "# wa_21_pred.to_csv(EXPORT_PATH+\"/naive_models/wa_21.csv\", header=True, index=False)\n",
    "\n",
    "wa_28_pred = wa_28.forecast(h=21, df = df_naive_train)\n",
    "wa_28_pred = wa_28_pred.reset_index()\n",
    "wa_28_pred = convert_to_sub_csv(wa_28_pred, \"WindowAverage\")\n",
    "# wa_28_pred.to_csv(EXPORT_PATH+\"/naive_models/wa_28.csv\", header=True, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict to compare RMSE on the 20% split\n",
    "\n",
    "NOTE: Takes about 8m to run the code chunk below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wa_12 = wa_12.forecast(h = h, df = train)\n",
    "df_wa_12 = df_wa_12.reset_index().merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "df_wa_14 = wa_14.forecast(h = h, df = train)\n",
    "df_wa_14 = df_wa_14.reset_index().merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "df_wa_21 = wa_21.forecast(h = h, df = train)\n",
    "df_wa_21 = df_wa_21.reset_index().merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "df_wa_28 = wa_28.forecast(h = h, df = train)\n",
    "df_wa_28 = df_wa_28.reset_index().merge(valid, on=['ds', 'unique_id'], how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that RMSE gradually decreases with increasing window sizes. Testing on greater window sizes beyond 28 increases Kaggle RMSE (graph in presentation slide 20).\n",
    "So the ideal window length is about 21 - 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.777953544392085\n",
      "2.7284115552768027\n",
      "2.6655059744910456\n",
      "2.6392974023341615\n"
     ]
    }
   ],
   "source": [
    "print_rmse(df_wa_12[\"y\"], df_wa_12[\"WindowAverage\"])\n",
    "print_rmse(df_wa_14[\"y\"], df_wa_14[\"WindowAverage\"])\n",
    "print_rmse(df_wa_21[\"y\"], df_wa_21[\"WindowAverage\"])\n",
    "print_rmse(df_wa_28[\"y\"], df_wa_28[\"WindowAverage\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETS model: HoltWinters (season length = 7)\n",
    "Performed second best overall compared to the rest of the modelling techniques (i.e. SARIMA, ML modelling) and WindowAverage\n",
    "\n",
    "However, due to the computational cost, the training was done on only on 50% of the dataset.\n",
    "\n",
    "Also tried other ETS models, such as simple exponential smoothing, and seasonal exp. smoothing, but they were not as good as HoltWinters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the last 50% of the time series because of computation\n",
    "df_naive_train = df_naive_train.set_index(\"ds\")\n",
    "df_naive_train = df_naive_train.sort_index()\n",
    "df_naive_train[\"ds\"] = df_naive_train.index\n",
    "\n",
    "# Find midpoint\n",
    "midpoint = start_date + ((end_date - start_date) / 2)\n",
    "\n",
    "# Split into train and validation, from midpoint onwards\n",
    "df_naive_train_subset = df_naive_train.loc[midpoint:]\n",
    "\n",
    "# find date to split, 80% of subset\n",
    "test_split_date = ((end_date - midpoint) * 0.8) + midpoint\n",
    "\n",
    "# Reset index of train dataset\n",
    "df_naive_train_subset = df_naive_train_subset.drop(\"ds\", axis = 1)\n",
    "df_naive_train_subset = df_naive_train_subset.reset_index()\n",
    "\n",
    "# Split by date\n",
    "train = df_naive_train_subset.loc[df_naive_train_subset['ds'] < test_split_date]\n",
    "valid = df_naive_train_subset.loc[(df_naive_train_subset['ds'] >= test_split_date)]\n",
    "\n",
    "h = valid['ds'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use the last 20% of the 50% split to train HoltWinters because running on the entire 50% split took longer than 30 mins. \n",
    "\n",
    "NOTE: below chunk took 12.5 mins to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt_winters = StatsForecast(models=[HoltWinters(season_length=7)],\n",
    "                      freq='D', n_jobs=-1)\n",
    "\n",
    "# Use the last 20% to train. \n",
    "holt_winters_pred = holt_winters.forecast(h = 21, df = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt_winters_pred = holt_winters_pred.reset_index()\n",
    "holt_winters_sub = convert_to_sub_csv(holt_winters_pred, \"HoltWinters\")\n",
    "# holt_winters_sub.to_csv(\"../submissions/naive_models/holt_winters.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing other baseline models (not top submissions, so don't need to run the code below this)\n",
    "With Naive, SeasonalNaive, WindowAverage, Seasonal Window Average models\n",
    "- Testing for different seasons and window sizes (multiples of 7, because that was the seasonality we detected in the EDA)\n",
    "\n",
    "Overall looking at the RMSE below, naive seemed to perform the best, followed by seasonal window average, then seasonal naive. \n",
    "\n",
    "It is strange that if naive method performed the best, we would presumse that seasonal naive would be better, or at least be 2nd place. More work could be done in EDA on the predictions to compare the trends and descriptive statistics to see whether the predictions are in line with the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>Naive</th>\n",
       "      <th>SeasonalNaive</th>\n",
       "      <th>SeasWA</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                unique_id         ds  Naive  SeasonalNaive  SeasWA  y\n",
       "0  Beauty_1_001_Central_1 2015-10-22    1.0            0.0     0.0  0\n",
       "1  Beauty_1_001_Central_1 2015-10-23    1.0            0.0     0.5  0\n",
       "2  Beauty_1_001_Central_1 2015-10-24    1.0            1.0     0.5  0\n",
       "3  Beauty_1_001_Central_1 2015-10-25    1.0            0.0     0.5  0\n",
       "4  Beauty_1_001_Central_1 2015-10-26    1.0            0.0     0.0  0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StatsForecast(models=[Naive(), \n",
    "                              SeasonalNaive(season_length=7), \n",
    "                              SeasonalWindowAverage(window_size=2, season_length=7)],\n",
    "                      freq='D', n_jobs=-1)\n",
    "\n",
    "p = model.fit_predict(h=h, df = train)\n",
    "p = p.reset_index().merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5222606586103105\n",
      "4.96096247060974\n",
      "4.886322395297068\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(valid[\"y\"], p[\"Naive\"])))\n",
    "print(np.sqrt(mean_squared_error(valid[\"y\"], p[\"SeasonalNaive\"])))\n",
    "print(np.sqrt(mean_squared_error(valid[\"y\"], p[\"SeasWA\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rmse(p[\"y\"], p[\"Naive\"])\n",
    "print_rmse(p[\"y\"], p[\"SeasonalNaive\"])\n",
    "print_rmse(p[\"y\"], p[\"SeasWA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>SeasonalNaive</th>\n",
       "      <th>SeasWA</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beauty_1_001_Central_1</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                unique_id         ds  SeasonalNaive  SeasWA  y\n",
       "0  Beauty_1_001_Central_1 2015-10-22            0.0     0.0  0\n",
       "1  Beauty_1_001_Central_1 2015-10-23            1.0     1.0  0\n",
       "2  Beauty_1_001_Central_1 2015-10-24            0.0     0.5  0\n",
       "3  Beauty_1_001_Central_1 2015-10-25            1.0     1.0  0\n",
       "4  Beauty_1_001_Central_1 2015-10-26            0.0     0.0  0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = StatsForecast(models=[SeasonalNaive(season_length=14), \n",
    "                              SeasonalWindowAverage(window_size=2, season_length=14)],\n",
    "                      freq='D', n_jobs=-1)\n",
    "\n",
    "p_2 = model_2.fit_predict(h=h, df = train)\n",
    "p_2 = p_2.reset_index().merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "p_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.07329627993835\n",
      "4.862353096961041\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(valid[\"y\"], p_2[\"SeasonalNaive\"])))\n",
    "print(np.sqrt(mean_squared_error(valid[\"y\"], p_2[\"SeasWA\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive models: Conclusion and Future work \n",
    "WindowAverage (WA) models consistently performed the best compared to others, though with more data, HoltWinters may be able to surpass WindowAverage, as currently the HoltWinters model here is only using the last 10% (0.5 * 0.2 = 0.1) of train data to produce its 21 day forecast.\n",
    "\n",
    "Though for some reason seasonal models performed worse compared to WA, the increasing performance by increasing window length by multiples of 7 until 21 - 28 suggests that some seasonality is still captured by the model.\n",
    "\n",
    "Further work:\n",
    "- Test the same models with differenced data. If we make time series stationary, perhaps window average would be even better because model does not account for seasonality. However, seasonal models may also perform better because even though the data could be differenced by 7, there could be some seasonality for the next 7 days which may be better captured by seasonal models. \n",
    "- Investigate why seasonal models did not perform better than non-seasonal models, even when accounting for different windows and season sizes. If the data was seasonal, we would assume that seasonal models would do better than non-seasonal models.\n",
    "- EDA could be conducted to compare the variance and trending of the predictions given by each model, to assess if the predictions are following the trend of the existing data. Though a model may have a higher RMSE, if the trending / seasonality of the predicted data better fits the train data, perhaps it is an issue of using more data points to train the model rather than the model itself not being suitable for prediction.\n",
    "- There were also some other naive models that we didn't try, such as historic average, or auto ETS. Auto ETS would be much more computationally intensive than WindowAverage, and as we have seen, even HoltWinters didn't give better performance than WindowAverage, even though it took more than 20 times longer to train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
